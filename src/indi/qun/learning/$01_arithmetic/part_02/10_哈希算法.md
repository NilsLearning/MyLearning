---
概要: 学习算法-哈希算法

---


### 1.什么叫哈希算法
将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值

### 2.哈希算法的特点
- 1.从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）;
- 2.对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- 3.散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
- 4.哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

### 3.哈希算法的应用:
- 1.安全加密
  密码信息经过加密后存放到数据库
- 2.唯一标识
  海量图片生成唯一标识，查找容易
- 3.数据校验
  以下载一个1G的电影来说，会先将这个文件切割成100个文件块，当所有文件块下载完成后，组装成一个就可以了。
  那么如何防止这100个文件块在下载过程中有被篡改的情况呢？这里以哈希算法做一个方案：
  可以将这100个文件块分别生成一个哈希值存放到一个文件中，然后将下载好的文件进行哈希后与之前保存的100个文件块的哈希值
  进行比对，若结果一一吻合，则文件下载成功，否则需要重新下载对应不上的数据
- 4.散列函数   
*哈希算法是如何解决这些分布式问题的*
- 5.负载均衡
如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢？也就是说，我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。        
最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器        
我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。

- 6.数据分片
如何统计“搜索关键词”出现的次数？
我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。具体的思路是这样的：为了提高处理的速度，我们用 n 台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。   
这样，哈希值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。     
这里的处理过程也是 MapReduce 的基本设计思想。

- 7.分布式存储
现在互联网面对的都是海量的数据、海量的用户。我们为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。于是，我们就需要将数据分布在多台机器上。该如何决定将哪个数据放到哪个机器上呢？     
我们可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。       
但是，如果数据增多，原来的 10 个机器已经无法承受了，我们就需要扩容了，比如扩到 11 个机器，这时候麻烦就来了。因为，这里并不是简单地加个机器就可以了。        
原来的数据是通过与 10 来取模的。比如 13 这个数据，存储在编号为 3 这台机器上。但是新加了一台机器中，我们对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上了。
因此，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。     
所以，我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，一致性哈希算法就要登场了。     
假设我们有 k 个机器，数据的哈希值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。       
一致性哈希算法的基本思想就是这么简单。除此之外，它还会借助一个虚拟的环和虚拟结点，更加优美地实现出来。

